# 金融大数据实验2

## 设计思路

本次实验的四个作业整体上和lab5差不多，只是数据处理中要考虑的情况更多，同时多了一个开放的任务4.

### 任务1

任务1要求统计每日总资金流入/流出量，通过分析，将任务分解为读取数据，按日期为key进行分类，最后reduce处理，计算每日资金流入流出三个部分，设计相应的map和reduce去处理。

最终的运行结果类似下表，完整结果见output/task1：

```
20130701	32488348,5525022
20130702	29037390,2554548
20130703	27270770,5953867
20130704	18321185,6410729
20130705	11648749,2763587
20130706	36751272,1616635
```

### 任务2

和任务1类似，只需要在任务一已有的基础上，通过借助output/task1文件，分析一周七天的总资金流入即可，关于日期的转换，通过上网搜索，发现了`DateTimeFormatter`和`LocalDate`两个类，可方便的进行日期转换。

最终的运行结果：
```
TUESDAY	2.6358205886885247E8,1.9176914462295082E8
MONDAY	2.6030581E8,2.174638654918033E8
WEDNESDAY	2.5416260783606556E8,1.946394465081967E8
THURSDAY	2.3642559403278688E8,1.764666748852459E8
FRIDAY	1.9940792306557378E8,1.6646796019672132E8
SUNDAY	1.5591455193442622E8,1.3242720506557377E8
SATURDAY	1.4808806829508197E8,1.1286894208196722E8
```

### 任务3

任务3需要判断用户的活跃情况，整体处理方式和任务1类似，将任务分解为读取数据，按用户id分类，最后reduce统计活跃次数，并降序输出三个部分，注意对空值的判断即可。

最终的运行结果（部分）：

```
7629	384
11818	359
21723	334
19140	332
24378	315
26395	297
25147	295
27719	293
20515	291
5016	287
```

### 任务4

任务4是个开放性问题，我分析的因素是mfd_day_share_interest.csv文件中的余额宝7日年化收益率字段（mfd_7daily_yield），分析这一利率与日均交易资金量之间的关系。

总体思路是：将`mfd_day_share_interest.csv` 文件预先读取（通过重载setup方法），然后用HashMap记录日期 -> 7日年化收益率，map阶段读取output/task1，并通过哈希查找将每个日期的资金流入流出和7日年化收益率对应起来，交给reduce处理。reduce阶段类似task2，统计并求平均即可。最后，将输出的结果用另一个java文件（Analysis_related.java）去分析，得到了相关系数，证明了有显著影响。

结果1（根据7日年化收益率得到的日均资金流入流出量，格式为收益率区间 流入量 流出量，即output/task4）：
```
4-5	159365440,152664975
5-6	234931629,189426341
6-7	378151919,195203850
```

结果2（最终的相关系数）：

利率与资金流入量的相关系数: 0.9844345053172856
利率与资金流出量的相关系数: 0.9218101798343007

## 可能的改进

- task2中，输出感觉最好保留到整数，而不是科学计数法输出
- 最终计算相关系数的java文件，是直接把数据写死到里面去计算的，下次最好改为通过读取结果文件去计算

## 其他说明

git仓库中还有一个`try.ipynb`文件，这是我写的用于简单查看数据/本地验证结果是否正确的python文件，起到了帮我快速统计数据（如task4中之所以分类为4-5,5-6,6-7这三个区间，就是先使用python发现数据的最大值为6.76，最小值为4.11，才决定这样分类），侧面验证的作用。